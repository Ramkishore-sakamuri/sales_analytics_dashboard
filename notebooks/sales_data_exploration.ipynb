{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Data Exploration\n",
    "\n",
    "This notebook is for exploring the sales dataset. We will perform initial data loading, cleaning, and visualization to understand the data's structure, identify patterns, and derive preliminary insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Configure visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.options.display.max_columns = None # Show all columns\n",
    "pd.options.plotting.backend = 'plotly' # Use Plotly for pandas plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load the sample sales data. Adjust the `file_path` if your data is located elsewhere. We're assuming the notebook is in a `notebooks/` directory and the data is in a parallel `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/sample_sales_data.csv' # Adjust path as needed\n",
    "try:\n",
    "    df_sales = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}. Please check the path.\")\n",
    "    # Create a dummy DataFrame for demonstration if file is not found\n",
    "    data = {\n",
    "        'OrderID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'OrderDate': pd.to_datetime(['2024-01-15', '2024-01-17', '2024-01-20', '2024-02-10', '2024-02-12', '2024-03-05', '2024-03-10', '2024-04-01', '2024-04-05', '2024-04-10']),\n",
    "        'ProductCategory': ['Electronics', 'Books', 'Electronics', 'Clothing', 'Books', 'Electronics', 'Clothing', 'Home Goods', 'Books', 'Electronics'],\n",
    "        'ProductName': ['Laptop', 'Python Programming', 'Smartphone', 'T-Shirt', 'Data Science Handbook', 'Tablet', 'Jeans', 'Desk Lamp', 'Statistics', 'Monitor'],\n",
    "        'Quantity': [2, 10, 5, 20, 5, 3, 15, 8, 12, 2],\n",
    "        'UnitPrice': [1200, 45, 800, 25, 55, 600, 70, 30, 50, 300],\n",
    "        'Salesperson': ['Alice', 'Bob', 'Alice', 'Carol', 'Bob', 'Alice', 'David', 'Carol', 'Bob', 'Alice'],\n",
    "        'Region': ['North', 'West', 'North', 'East', 'West', 'North', 'South', 'East', 'West', 'North']\n",
    "    }\n",
    "    df_sales = pd.DataFrame(data)\n",
    "    df_sales['TotalSale'] = df_sales['Quantity'] * df_sales['UnitPrice']\n",
    "    print(\"Loaded dummy data for demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows:\")\n",
    "display(df_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLast 5 rows:\")\n",
    "display(df_sales.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataframe Info:\")\n",
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(df_sales.describe(include='all')) # include='all' for both numeric and object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nShape of the dataframe: {df_sales.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "display(df_sales.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNumber of duplicated rows: {df_sales.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing\n",
    "\n",
    "Based on the initial inspection, perform necessary cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'OrderDate' to datetime if not already (should be handled by read_csv's parse_dates or done manually)\n",
    "if 'OrderDate' in df_sales.columns and not pd.api.types.is_datetime64_any_dtype(df_sales['OrderDate']):\n",
    "    df_sales['OrderDate'] = pd.to_datetime(df_sales['OrderDate'])\n",
    "    print(\"'OrderDate' converted to datetime.\")\n",
    "\n",
    "# Example: Handle missing values (if any were found)\n",
    "# For numerical columns, you might fill with mean or median\n",
    "# For categorical columns, you might fill with mode or a specific placeholder\n",
    "# e.g., df_sales['SomeNumericColumn'].fillna(df_sales['SomeNumericColumn'].median(), inplace=True)\n",
    "# e.g., df_sales['SomeCategoricalColumn'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Example: Remove duplicates (if any significant number were found and are actual duplicates)\n",
    "# df_sales.drop_duplicates(inplace=True)\n",
    "\n",
    "# Feature Engineering: Extract useful features from OrderDate\n",
    "if 'OrderDate' in df_sales.columns:\n",
    "    df_sales['Year'] = df_sales['OrderDate'].dt.year\n",
    "    df_sales['Month'] = df_sales['OrderDate'].dt.month\n",
    "    df_sales['MonthName'] = df_sales['OrderDate'].dt.month_name()\n",
    "    df_sales['Day'] = df_sales['OrderDate'].dt.day\n",
    "    df_sales['DayOfWeek'] = df_sales['OrderDate'].dt.day_name()\n",
    "    df_sales['Quarter'] = df_sales['OrderDate'].dt.to_period('Q').astype(str)\n",
    "    print(\"Date features extracted.\")\n",
    "\n",
    "# Calculate TotalSale if not present (it was in the sample CSV but good practice to check)\n",
    "if 'Quantity' in df_sales.columns and 'UnitPrice' in df_sales.columns and 'TotalSale' not in df_sales.columns:\n",
    "    df_sales['TotalSale'] = df_sales['Quantity'] * df_sales['UnitPrice']\n",
    "    print(\"'TotalSale' column calculated.\")\n",
    "\n",
    "display(df_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df_sales.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "for col in ['Quantity', 'UnitPrice', 'TotalSale']:\n",
    "    if col in df_sales.columns:\n",
    "        fig = px.histogram(df_sales, x=col, title=f'Distribution of {col}', marginal='box')\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df_sales.select_dtypes(include='object').columns.tolist()\n",
    "# Also include 'MonthName', 'DayOfWeek', 'Quarter' if they were created\n",
    "if 'MonthName' in df_sales.columns: categorical_cols.append('MonthName') # Example\n",
    "print(f\"Categorical columns for count plots: {categorical_cols}\")\n",
    "\n",
    "for col in ['ProductCategory', 'Salesperson', 'Region', 'MonthName']:\n",
    "    if col in df_sales.columns:\n",
    "        fig = px.bar(df_sales[col].value_counts().reset_index(), \n",
    "                     x='index', y=col, title=f'Counts of {col}',\n",
    "                     labels={'index': col, col: 'Count'})\n",
    "        fig.update_layout(xaxis_title=col, yaxis_title='Count')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Bivariate and Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OrderDate' in df_sales.columns and 'TotalSale' in df_sales.columns:\n",
    "    # Ensure OrderDate is sorted for time series plotting\n",
    "    df_time_sales = df_sales.sort_values('OrderDate').set_index('OrderDate')['TotalSale'].resample('M').sum().reset_index()\n",
    "    fig = px.line(df_time_sales, x='OrderDate', y='TotalSale', title='Monthly Sales Over Time', markers=True)\n",
    "    fig.show()\n",
    "    \n",
    "    # Quarterly Sales\n",
    "    df_quarterly_sales = df_sales.groupby('Quarter')['TotalSale'].sum().reset_index()\n",
    "    fig_quarterly = px.bar(df_quarterly_sales, x='Quarter', y='TotalSale', title='Total Sales per Quarter')\n",
    "    fig_quarterly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ProductCategory' in df_sales.columns and 'TotalSale' in df_sales.columns:\n",
    "    category_sales = df_sales.groupby('ProductCategory')['TotalSale'].sum().sort_values(ascending=False).reset_index()\n",
    "    fig = px.bar(category_sales, x='ProductCategory', y='TotalSale', \n",
    "                 title='Total Sales by Product Category', color='ProductCategory')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Region' in df_sales.columns and 'TotalSale' in df_sales.columns:\n",
    "    region_sales = df_sales.groupby('Region')['TotalSale'].sum().sort_values(ascending=False).reset_index()\n",
    "    fig = px.pie(region_sales, values='TotalSale', names='Region', title='Sales Distribution by Region', hole=0.3)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales by Salesperson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Salesperson' in df_sales.columns and 'TotalSale' in df_sales.columns:\n",
    "    salesperson_performance = df_sales.groupby('Salesperson')['TotalSale'].sum().sort_values(ascending=False).reset_index()\n",
    "    fig = px.bar(salesperson_performance, x='Salesperson', y='TotalSale', \n",
    "                 title='Total Sales by Salesperson', color='Salesperson')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis (Numerical Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numerical_cols) > 1:\n",
    "    # Select only numerical columns for correlation that make sense (e.g., exclude Year, Month if not desired for this specific heatmap)\n",
    "    cols_for_corr = ['Quantity', 'UnitPrice', 'TotalSale']\n",
    "    # Filter out columns that might not exist in the dummy data or are not suitable\n",
    "    cols_for_corr = [col for col in cols_for_corr if col in df_sales.columns and pd.api.types.is_numeric_dtype(df_sales[col])]\n",
    "    \n",
    "    if len(cols_for_corr) > 1:\n",
    "        correlation_matrix = df_sales[cols_for_corr].corr()\n",
    "        fig = px.imshow(correlation_matrix, text_auto=True, aspect=\"auto\",\n",
    "                        title='Correlation Matrix of Numerical Features',\n",
    "                        color_continuous_scale='RdBu_r') # Red-Blue diverging scale\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Not enough numerical columns for a meaningful correlation matrix.\")\n",
    "else:\n",
    "    print(\"No numerical columns found for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Performance (e.g., Top N Products by Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ProductName' in df_sales.columns and 'TotalSale' in df_sales.columns:\n",
    "    top_n = 10\n",
    "    product_sales = df_sales.groupby('ProductName')['TotalSale'].sum().sort_values(ascending=False).head(top_n).reset_index()\n",
    "    fig = px.bar(product_sales, x='ProductName', y='TotalSale', \n",
    "                 title=f'Top {top_n} Products by Sales', color='ProductName')\n",
    "    fig.update_layout(xaxis_title='Product Name', yaxis_title='Total Sales')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary of Initial Findings and Next Steps\n",
    "\n",
    "Based on the exploration:\n",
    "\n",
    "1.  **Data Quality:** (Comment on missing values, duplicates, data types after cleaning)\n",
    "2.  **Key Trends:** (e.g., \"Sales peak in Q4\", \"Electronics is the highest-grossing category\")\n",
    "3.  **Top Performers:** (e.g., \"Salesperson X has the highest sales\", \"Product Y is the best-seller\")\n",
    "4.  **Regional Performance:** (e.g., \"North region contributes the most to sales\")\n",
    "5.  **Potential Issues/Further Questions:** (e.g., \"Why did sales dip in June?\", \"Is there a correlation between unit price and quantity sold for specific categories?\")\n",
    "\n",
    "**Next Steps:**\n",
    "* Deeper dive into specific segments.\n",
    "* Time series forecasting if applicable.\n",
    "* Customer segmentation.\n",
    "* Prepare data for BI dashboard (aggregations, specific metrics)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
